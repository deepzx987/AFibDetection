{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from os import listdir, mkdir, system\n",
    "from os.path import isfile, isdir, join, exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from keras import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv1D, BatchNormalization, Dropout, MaxPooling1D, Flatten, Dense, LSTM, Input, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "import itertools\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)\n",
    "fs = 300\n",
    "input_dir = 'One_Hot_Data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install keras tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, name, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.savefig('ResNet/'+name+'_confmat.png',dpi=250)\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data and modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "(61836, 1200, 1)\n",
      "(61836, 4)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 1200, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 1200, 64)     1088        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 1200, 64)     256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 1200, 64)     0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 1200, 64)     65600       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 1200, 64)     256         conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 1200, 64)     0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1200, 64)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 1200, 64)     65600       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 600, 64)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 600, 64)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 600, 64)      0           max_pooling1d_3[0][0]            \n",
      "                                                                 max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 600, 64)      256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 600, 64)      0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 600, 64)      0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 600, 64)      65600       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 600, 64)      256         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 600, 64)      0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 600, 64)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 600, 64)      65600       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 600, 64)      0           conv1d_10[0][0]                  \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 600, 64)      256         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 600, 64)      0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 38400)        0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 4)            153604      flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 418,372\n",
      "Trainable params: 417,732\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n",
      "Train on 50086 samples, validate on 5566 samples\n",
      "Epoch 1/1\n",
      "50086/50086 [==============================] - 1573s 31ms/step - loss: 1.2301 - acc: 0.4766 - val_loss: 1.0160 - val_acc: 0.5347\n",
      "TP,FP,TN,FN,Precision,Accuracy,Sensitivity,Specificity,F1Score,AUC\n",
      "895 , 862 , 3282 , 1145 , 50.94% , 67.55% , 43.87% , 79.20% , 47.14% , 61.54%\n",
      "792 , 581 , 4384 , 427 , 57.68% , 83.70% , 64.97% , 88.30% , 61.11% , 76.63%\n",
      "895 , 993 , 3098 , 1198 , 47.40% , 64.57% , 42.76% , 75.73% , 44.96% , 59.24%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.44      0.47      2040\n",
      "           1       0.58      0.65      0.61      1219\n",
      "           2       0.47      0.43      0.45      2093\n",
      "           3       0.67      0.94      0.79       832\n",
      "\n",
      "   micro avg       0.54      0.54      0.54      6184\n",
      "   macro avg       0.56      0.62      0.58      6184\n",
      "weighted avg       0.53      0.54      0.53      6184\n",
      " samples avg       0.54      0.54      0.54      6184\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "(41222, 1800, 1)\n",
      "(41222, 4)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 1800, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 1800, 64)     1088        input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 1800, 64)     256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 1800, 64)     0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 1800, 64)     65600       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 1800, 64)     256         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 1800, 64)     0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 1800, 64)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 1800, 64)     65600       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 900, 64)      0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 900, 64)      0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 900, 64)      0           max_pooling1d_5[0][0]            \n",
      "                                                                 max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 900, 64)      256         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 900, 64)      0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 900, 64)      0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 900, 64)      65600       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 900, 64)      256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 900, 64)      0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 900, 64)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 900, 64)      65600       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 900, 64)      0           conv1d_15[0][0]                  \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 900, 64)      256         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 900, 64)      0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 57600)        0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 4)            230404      flatten_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 495,172\n",
      "Trainable params: 494,532\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n",
      "Train on 33389 samples, validate on 3710 samples\n",
      "Epoch 1/1\n",
      "  256/33389 [..............................] - ETA: 27:34 - loss: 5.5215 - acc: 0.3203"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-342bccc6ae6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     history = model.fit(X_train, y_train, batch_size=64, epochs=1, verbose=1, validation_data=(X_val, y_val), \n\u001b[0;32m---> 94\u001b[0;31m             callbacks=[EarlyStopping(monitor='val_loss', patience=10, verbose=1)])\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for f in listdir(input_dir):\n",
    "    \n",
    "    print (f.split(\".\")[0])\n",
    "    OUTPUT_CLASS = 4  # output classes\n",
    "    k = 1  # increment every 4th residual block\n",
    "    p = True  # pool toggle every other residual block (end with 2^8)\n",
    "    convfilt = 64\n",
    "    convstr = 1\n",
    "    ksize = 16\n",
    "    poolsize = 2\n",
    "    poolstr = 2\n",
    "    drop = 0.5\n",
    "    df = pd.read_csv(join(input_dir,f), header=None)\n",
    "    data = df.values\n",
    "    X = data[:,:-4]\n",
    "    X.shape\n",
    "    X = X.reshape(-1, X.shape[1], 1)\n",
    "    y = data[:,-4:]\n",
    "    print (X.shape)\n",
    "    print (y.shape)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=1, shuffle=True)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1, shuffle=True)\n",
    "    \n",
    "    input1 = Input(shape=(X_train.shape[1],1), name='input')\n",
    "\n",
    "    ## First convolutional block (conv,BN, relu)\n",
    "    x = Conv1D(filters=convfilt, kernel_size=ksize, padding='same', strides=convstr, kernel_initializer='he_normal')(input1)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    ## Second convolutional block (conv, BN, relu, dropout, conv) with residual net\n",
    "    # Left branch (convolutions)\n",
    "    x1 = Conv1D(filters=convfilt, kernel_size=ksize, padding='same', strides=convstr, kernel_initializer='he_normal')(x)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Dropout(drop)(x1)\n",
    "    x1 = Conv1D(filters=convfilt, kernel_size=ksize, padding='same', strides=convstr, kernel_initializer='he_normal')(x1)\n",
    "    x1 = MaxPooling1D(pool_size=poolsize, strides=poolstr)(x1)\n",
    "\n",
    "    # Right branch, shortcut branch pooling\n",
    "    x2 = MaxPooling1D(pool_size=poolsize, strides=poolstr)(x)\n",
    "\n",
    "    # Merge both branches\n",
    "    x = keras.layers.add([x1, x2])\n",
    "\n",
    "    del x1, x2\n",
    "\n",
    "    ## Main loop\n",
    "    p = not p\n",
    "    for l in range(5):\n",
    "\n",
    "        if (l % 4 == 0) and (l > 0):  # increment k on every fourth residual block\n",
    "            k += 1\n",
    "            # increase depth by 1x1 Convolution case dimension shall change\n",
    "            xshort = Conv1D(filters=convfilt * k, kernel_size=1)(x)\n",
    "        else:\n",
    "            xshort = x\n",
    "            # Left branch (convolutions)\n",
    "        # notice the ordering of the operations has changed\n",
    "        x1 = BatchNormalization()(x)\n",
    "        x1 = Activation('relu')(x1)\n",
    "        x1 = Dropout(drop)(x1)\n",
    "        x1 = Conv1D(filters=convfilt * k, kernel_size=ksize, padding='same', strides=convstr, kernel_initializer='he_normal')(x1)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = Activation('relu')(x1)\n",
    "        x1 = Dropout(drop)(x1)\n",
    "        x1 = Conv1D(filters=convfilt * k, kernel_size=ksize, padding='same', strides=convstr, kernel_initializer='he_normal')(x1)\n",
    "        if p:\n",
    "            x1 = MaxPooling1D(pool_size=poolsize, strides=poolstr)(x1)\n",
    "\n",
    "            # Right branch: shortcut connection\n",
    "        if p:\n",
    "            x2 = MaxPooling1D(pool_size=poolsize, strides=poolstr)(xshort)\n",
    "        else:\n",
    "            x2 = xshort  # pool or identity\n",
    "        # Merging branches\n",
    "        x = keras.layers.add([x1, x2])\n",
    "        # change parameters\n",
    "        p = not p  # toggle pooling\n",
    "\n",
    "    # Final bit\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    # x = Dense(1000)(x)\n",
    "    # x = Dense(1000)(x)\n",
    "    out = Dense(OUTPUT_CLASS, activation='softmax')(x)\n",
    "    model = Model(inputs=input1, outputs=out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    history = model.fit(X_train, y_train, batch_size=128, epochs=250, verbose=1, validation_data=(X_val, y_val), \n",
    "            callbacks=[EarlyStopping(monitor='val_loss', patience=15, verbose=1)])\n",
    "    \n",
    "    \n",
    "    accuracy = history.history['acc']\n",
    "    val_accuracy = history.history['val_acc']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(accuracy))\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "    plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.savefig('ResNet/'+f[0]+'_acc.png',dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(epochs, loss, label='Training loss')\n",
    "    plt.plot(epochs, val_loss, label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.savefig('ResNet/'+f[0]+'_loss.png',dpi=200)\n",
    "    plt.close()\n",
    "\n",
    "    model.save('ResNet/'+f[0]+\"_model.h5py\")\n",
    "    \n",
    "    new_y_pred = model.predict(X_test)\n",
    "    y_test_arg = np.argmax(np.round(y_test),axis=1)\n",
    "    y_pred_arg = np.argmax(np.round(new_y_pred),axis=1)\n",
    "    y_pred = np.zeros((new_y_pred.shape[0],new_y_pred.shape[1]))\n",
    "\n",
    "    from pycm import *\n",
    "    cm = ConfusionMatrix(actual_vector=y_test_arg, predict_vector=y_pred_arg)\n",
    "    totalt = cm.__dict__\n",
    "\n",
    "    TP = totalt['TP']\n",
    "    FP = totalt['FP']\n",
    "    TN = totalt['TN']\n",
    "    FN = totalt['FN']\n",
    "\n",
    "    PPV = totalt['PPV']\n",
    "    ACC = totalt['ACC']\n",
    "    SEN = totalt['TPR']\n",
    "    SPE = totalt['TNR']\n",
    "    F1S = totalt['F1']\n",
    "    AUC = totalt['AUC']\n",
    "\n",
    "    print ('TP,FP,TN,FN,Precision,Accuracy,Sensitivity,Specificity,F1Score,AUC')\n",
    "    print (TP[0], ',', FP[0], ',', TN[0], ',', FN[0], ',', '{:.2f}%'.format(PPV[0]*100), ',', '{:.2f}%'.format(ACC[0]*100), ',', '{:.2f}%'.format(SEN[0]*100), ',','{:.2f}%'.format(SPE[0]*100), ',','{:.2f}%'.format(F1S[0]*100), ',','{:.2f}%'.format(AUC[0]*100))\n",
    "    print (TP[1], ',', FP[1], ',', TN[1], ',', FN[1], ',', '{:.2f}%'.format(PPV[1]*100), ',','{:.2f}%'.format(ACC[1]*100), ',','{:.2f}%'.format(SEN[1]*100), ',','{:.2f}%'.format(SPE[1]*100), ',','{:.2f}%'.format(F1S[1]*100), ',','{:.2f}%'.format(AUC[1]*100))\n",
    "    print (TP[2], ',', FP[2], ',', TN[2], ',', FN[2], ',', '{:.2f}%'.format(PPV[2]*100), ',','{:.2f}%'.format(ACC[2]*100), ',','{:.2f}%'.format(SEN[2]*100), ',','{:.2f}%'.format(SPE[2]*100), ',','{:.2f}%'.format(F1S[2]*100), ',','{:.2f}%'.format(AUC[2]*100))\n",
    "\n",
    "\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        y_pred[i][y_pred_arg[i]] = 1\n",
    "\n",
    "    print (classification_report(y_test, y_pred))\n",
    "    cnf_matrix = confusion_matrix(y_test_arg, y_pred_arg)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    class_names = ['Normal','AFiB','Other', 'Noisy']\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plot_confusion_matrix(cnf_matrix, name = f[0], classes=class_names, title='Confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.add(Flatten())\n",
    "\n",
    "# model.add(Dense(128, activation='relu'))\n",
    "# model.add(Dense(y.shape[1], activation='softmax'))\n",
    "\n",
    "\n",
    "# model.add(Conv2D(512, 3, strides=(32, 4), padding='same', input_shape=(1, 32, None)))\n",
    "# model.add(Reshape((512, -1)))\n",
    "# model.add(Permute((2, 1)))\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(200, activation='relu', input_shape=(X.shape[1],1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 81% recall. That means the model correctly identified 81% of the total bad loans. Thats pretty great. \n",
    "# But is this actually representative of how the model will perform? To find out, Ill calculate the accuracy \n",
    "# and recall for the model on the test dataset I created initially.\n",
    "# By oversampling before splitting into training and validation datasets, I bleed information from the\n",
    "# validation set into the training of the model.\n",
    "\n",
    "# To see how this works, think about the case of simple oversampling (where I just duplicate observations). \n",
    "# If I upsample a dataset before splitting it into a train and validation set, I could end up with the same \n",
    "# observation in both datasets. As a result, a complex enough model will be able to perfectly predict the value \n",
    "# for those observations when predicting on the validation set, inflating the accuracy and recall.\n",
    "\n",
    "# When upsampling using SMOTE, I dont create duplicate observations. However, because the SMOTE algorithm uses\n",
    "# the nearest neighbors of observations to create synthetic data, it still bleeds information. If the nearest \n",
    "# neighbors of minority class observations in the training set end up in the validation set, their information \n",
    "# is partially captured by the synthetic data in the training set. Since Im splitting the data randomly, wed\n",
    "# expect to have this happen. As a result, the model will be better able to predict validation set values than\n",
    "# completely new data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
